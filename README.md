# AI Deception Dashboard
# testing git push

## testing from the github web

This project explores how AI systems internally behave when producing truthful, deceptive, or withholding responses.

Rather than judging outputs as “lies,” this dashboard surfaces internal **deception signals** using interpretability techniques, including feature analysis and intervention. The goal is transparency — not verdicts.

## What this does
- Analyzes AI responses for deception-related internal patterns
- Distinguishes between fabrication vs withholding behaviors
- Visualizes confidence and feature-level contributions
- Demonstrates causal interventions via ablation

## What this does NOT do
- It does not claim intent or consciousness
- It does not guarantee correctness
- It is not a production lie detector

## Why this matters
As AI systems become more capable, understanding *how* and *why* they mislead matters as much as whether they do. This project provides a concrete, interpretable starting point.

## Status
Version 1 — research prototype and public demo.
